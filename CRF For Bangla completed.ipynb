{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e663737-624d-4f1d-8c04-5f8d7eb0f212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CRF For Bangla.ipynb'\t  N.inb         bengali-stemmer   nlp_hackathon_bd_2023\n",
      "'CRF for English.ipynb'   NLP.ipynb     ner.csv\n",
      " Getting_Started.ipynb\t  archive.zip   ner_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75fca457-d78b-4771-be70-962a245237a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getDatasetFromIBOFile(filename): #nlp_hackathon_bd_2023/data/dev.txt\"\n",
    "    f = open(filename, \"r\")\n",
    "    content = f.read()\n",
    "    \n",
    "    lines = content.split(\"\\n\")\n",
    "    \n",
    "    dataset = []\n",
    "    for line in lines:\n",
    "        parts = line.split(\" _ _ \")\n",
    "        word = parts[0]\n",
    "        label = parts[len(parts)-1]\n",
    "\n",
    "        dataset.append([word,label])\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80c01fe1-0bc6-4531-b2fa-4a7998d80c37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['তিনি', 'O'], ['যুবক', 'O'], ['হিসেবে', 'O'], ['শেফিল্ড', 'B-GRP'], ['বুধবার', 'I-GRP'], ['এফ.সি.', 'I-GRP'], ['যোগদান', 'O'], ['করেন', 'O'], ['এবং', 'O'], ['১৯৫১', 'O'], ['সালে', 'O'], ['তাদের', 'O'], ['পেশাগত', 'O'], ['দিক', 'O'], ['দিয়ে', 'O'], ['আত্মপ্রকাশ', 'O'], ['করেন।', 'O'], ['', ''], ['ভিনেগার', 'O'], ['মাঝে', 'O'], ['মাঝে', 'O'], ['চাটনি', 'B-PROD'], ['ব্যবহার', 'O'], ['করা', 'O'], ['হয়।', 'O'], ['', ''], ['মূলত,', 'O'], ['দুর্গটি', 'O'], ['ছিল', 'O'], ['একটি', 'O']]\n"
     ]
    }
   ],
   "source": [
    "dataset = getDatasetFromIBOFile(\"nlp_hackathon_bd_2023/data/dev.txt\")\n",
    "print(dataset[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "124c62a7-07e4-454e-952c-5d7bb4ca3722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: bltk in /opt/conda/lib/python3.7/site-packages (1.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from bltk) (0.22.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from bltk) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.7/site-packages (from bltk) (1.21.6)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from bltk) (0.14.1)\n",
      "Requirement already satisfied: certifi>=2019.11.28 in /opt/conda/lib/python3.7/site-packages (from bltk) (2022.9.24)\n",
      "Requirement already satisfied: nltk>=3.4.5 in /opt/conda/lib/python3.7/site-packages (from bltk) (3.7)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from bltk) (1.14.0)\n",
      "Requirement already satisfied: sklearn>=0.0 in /opt/conda/lib/python3.7/site-packages (from bltk) (0.0.post1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk>=3.4.5->bltk) (2022.10.31)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk>=3.4.5->bltk) (7.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk>=3.4.5->bltk) (4.42.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42857a69-4c48-4e8b-80cd-1908d2e197ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DictVectorizer from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from bltk.langtools import PosTagger\n",
    "pos_tagger = PosTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de0607c6-9fd9-4d1a-a8c0-06656687424b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert data into features\n",
    "\n",
    "feature_extracted_dataset = []\n",
    "sentence = []\n",
    "for row in dataset:\n",
    "    word = row[0]\n",
    "    label = row[1]\n",
    "    if word=='':\n",
    "        feature_extracted_dataset.append(sentence)\n",
    "        sentence = []\n",
    "        continue\n",
    "    basic_word_features = (word, pos_tagger.pos_tag([word])[0][1], label)\n",
    "    sentence.append(basic_word_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c2a1044-4615-4ef5-80f6-71f03b38a676",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('তিনি', 'PPR', 'O'), ('যুবক', 'NC', 'O'), ('হিসেবে', 'PP', 'O'), ('শেফিল্ড', 'NP', 'B-GRP'), ('বুধবার', 'NC', 'I-GRP'), ('এফ.সি.', 'NP', 'I-GRP'), ('যোগদান', 'NC', 'O'), ('করেন', 'VM', 'O'), ('এবং', 'CCD', 'O'), ('১৯৫১', 'RDX', 'O'), ('সালে', 'NC', 'O'), ('তাদের', 'PPR', 'O'), ('পেশাগত', 'JJ', 'O'), ('দিক', 'NC', 'O'), ('দিয়ে', 'VM', 'O'), ('আত্মপ্রকাশ', 'NC', 'O'), ('করেন।', 'VM', 'O')], [('ভিনেগার', 'NC', 'O'), ('মাঝে', 'NST', 'O'), ('মাঝে', 'NST', 'O'), ('চাটনি', 'NC', 'B-PROD'), ('ব্যবহার', 'NC', 'O'), ('করা', 'NV', 'O'), ('হয়।', 'VM', 'O')], [('মূলত,', 'NC', 'O'), ('দুর্গটি', 'NC', 'O'), ('ছিল', 'VM', 'O'), ('একটি', 'JQ', 'O'), ('সুরক্ষিত', 'JJ', 'O'), ('দুর্গ,', 'PU', 'O'), ('যা', 'PRL', 'O'), ('পোলিশ', 'NC', 'B-LOC'), ('-লিথুয়ানিয়ান', 'NC', 'I-LOC'), ('কমনওয়েলথ', 'NP', 'I-LOC'), ('এর', 'PPR', 'O'), ('দক্ষিণ', 'JJ', 'O'), ('সীমান্ত', 'NC', 'O'), ('রক্ষা', 'NC', 'O'), ('করে।', 'VM', 'O')], [('হার্নান্দেজ', 'NC', 'O'), ('আলোকচিত্রগ্রাহী', 'NC', 'B-PROD'), ('ফিল্ম', 'NP', 'I-PROD'), ('ক্যামেরা', 'NC', 'O'), ('ব্যবহার', 'NC', 'O'), ('করা', 'NV', 'O'), ('অব্যাহত', 'JJ', 'O'), ('রেখেছেন,', 'PU', 'O'), ('যদিও', 'CSB', 'O'), ('তার', 'PPR', 'O'), ('প্রিন্ট', 'JJ', 'O'), ('ডিজিটালভাবে', 'AMN', 'O'), ('উৎপাদিত', 'JJ', 'O'), ('হয়।', 'VM', 'O')], [('ভ্যারাইটি', 'NC', 'B-CORP'), ('সিরিজের', 'NC', 'O'), ('উজ্জ্বল,', 'PU', 'O'), ('অনলস', 'NP', 'O'), ('চেহারা', 'NC', 'O'), ('এবং', 'CCD', 'O'), ('এমনকি', 'CSB', 'O'), ('তত্ত্বের', 'NC', 'O'), ('একটি', 'JQ', 'O'), ('আকর্ষণীয়', 'JJ', 'O'), ('ভিত্তির', 'NC', 'O'), ('প্রশংসা', 'NC', 'O'), ('করেছেন।', 'VM', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "print(feature_extracted_dataset[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f91d95e-9bd1-45a1-838e-1788734d6f56",
   "metadata": {},
   "source": [
    "lets Add some cool features now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d04258b-89c3-442e-afc4-28acd5cd85cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def count_punctuations(text):\n",
    "    punctuations='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "    cnt = 0\n",
    "    for i in punctuations:\n",
    "        if i in text:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "print(count_punctuations(\"মূলত-প্রশংসা\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "42fecddf-b5fc-48da-a28d-56caef437de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        #'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        #'word.isupper()': word.isupper(),\n",
    "        #'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "        \"containPunctuation\": count_punctuations(word),\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            #'-1:word.lower()': word1.lower(),\n",
    "            #'-1:word.istitle()': word1.istitle(),\n",
    "            #'-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            #'+1:word.lower()': word1.lower(),\n",
    "            #'+1:word.istitle()': word1.istitle(),\n",
    "            #'+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3cfc18ca-9892-4218-80db-0ad2002a3217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in feature_extracted_dataset]\n",
    "y = [sent2labels(s) for s in feature_extracted_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ea6bc68-0c3c-4610-b698-98b492f6a7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'bias': 1.0,\n",
       "   'word[-3:]': 'িনি',\n",
       "   'word[-2:]': 'নি',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PPR',\n",
       "   'postag[:2]': 'PP',\n",
       "   'containPunctuation': 0,\n",
       "   'BOS': True,\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'ুবক',\n",
       "   'word[-2:]': 'বক',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'PPR',\n",
       "   '-1:postag[:2]': 'PP',\n",
       "   '+1:postag': 'PP',\n",
       "   '+1:postag[:2]': 'PP'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'েবে',\n",
       "   'word[-2:]': 'বে',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PP',\n",
       "   'postag[:2]': 'PP',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'NP',\n",
       "   '+1:postag[:2]': 'NP'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'ল্ড',\n",
       "   'word[-2:]': '্ড',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NP',\n",
       "   'postag[:2]': 'NP',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'PP',\n",
       "   '-1:postag[:2]': 'PP',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'বার',\n",
       "   'word[-2:]': 'ার',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NP',\n",
       "   '-1:postag[:2]': 'NP',\n",
       "   '+1:postag': 'NP',\n",
       "   '+1:postag[:2]': 'NP'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'সি.',\n",
       "   'word[-2:]': 'ি.',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NP',\n",
       "   'postag[:2]': 'NP',\n",
       "   'containPunctuation': 1,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'দান',\n",
       "   'word[-2:]': 'ান',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NP',\n",
       "   '-1:postag[:2]': 'NP',\n",
       "   '+1:postag': 'VM',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'রেন',\n",
       "   'word[-2:]': 'েন',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VM',\n",
       "   'postag[:2]': 'VM',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'CCD',\n",
       "   '+1:postag[:2]': 'CC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'এবং',\n",
       "   'word[-2:]': 'বং',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CCD',\n",
       "   'postag[:2]': 'CC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'VM',\n",
       "   '-1:postag[:2]': 'VM',\n",
       "   '+1:postag': 'RDX',\n",
       "   '+1:postag[:2]': 'RD'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': '৯৫১',\n",
       "   'word[-2:]': '৫১',\n",
       "   'word.isdigit()': True,\n",
       "   'postag': 'RDX',\n",
       "   'postag[:2]': 'RD',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'CCD',\n",
       "   '-1:postag[:2]': 'CC',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'ালে',\n",
       "   'word[-2:]': 'লে',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'RDX',\n",
       "   '-1:postag[:2]': 'RD',\n",
       "   '+1:postag': 'PPR',\n",
       "   '+1:postag[:2]': 'PP'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'দের',\n",
       "   'word[-2:]': 'ের',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PPR',\n",
       "   'postag[:2]': 'PP',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'াগত',\n",
       "   'word[-2:]': 'গত',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'PPR',\n",
       "   '-1:postag[:2]': 'PP',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'দিক',\n",
       "   'word[-2:]': 'িক',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:postag': 'VM',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'য়ে',\n",
       "   'word[-2:]': '়ে',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VM',\n",
       "   'postag[:2]': 'VM',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'কাশ',\n",
       "   'word[-2:]': 'াশ',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'VM',\n",
       "   '-1:postag[:2]': 'VM',\n",
       "   '+1:postag': 'VM',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'েন।',\n",
       "   'word[-2:]': 'ন।',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VM',\n",
       "   'postag[:2]': 'VM',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   'EOS': True}],\n",
       " [{'bias': 1.0,\n",
       "   'word[-3:]': 'গার',\n",
       "   'word[-2:]': 'ার',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   'BOS': True,\n",
       "   '+1:postag': 'NST',\n",
       "   '+1:postag[:2]': 'NS'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'াঝে',\n",
       "   'word[-2:]': 'ঝে',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NST',\n",
       "   'postag[:2]': 'NS',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'NST',\n",
       "   '+1:postag[:2]': 'NS'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'াঝে',\n",
       "   'word[-2:]': 'ঝে',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NST',\n",
       "   'postag[:2]': 'NS',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NST',\n",
       "   '-1:postag[:2]': 'NS',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'টনি',\n",
       "   'word[-2:]': 'নি',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NST',\n",
       "   '-1:postag[:2]': 'NS',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'হার',\n",
       "   'word[-2:]': 'ার',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'NV',\n",
       "   '+1:postag[:2]': 'NV'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'করা',\n",
       "   'word[-2:]': 'রা',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NV',\n",
       "   'postag[:2]': 'NV',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'VM',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'য়।',\n",
       "   'word[-2:]': '়।',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VM',\n",
       "   'postag[:2]': 'VM',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NV',\n",
       "   '-1:postag[:2]': 'NV',\n",
       "   'EOS': True}]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "581f62b0-94fc-4e6a-8291-c00bbabb26a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5be2d0cb-5363-4d8a-82f0-1f5f5842c39f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0.post1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e46fcafd-c6b0-471e-a068-7a66b8c014d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "be418288-72a6-4a09-842c-cfbd82bbcc86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-CORP       0.36      0.16      0.22       127\n",
      "        B-CW       0.10      0.03      0.04       120\n",
      "       B-GRP       0.47      0.34      0.39       118\n",
      "       B-LOC       0.40      0.23      0.29       101\n",
      "       B-PER       0.48      0.43      0.46       144\n",
      "      B-PROD       0.39      0.15      0.22       189\n",
      "      I-CORP       0.46      0.26      0.33       122\n",
      "        I-CW       0.24      0.07      0.11       161\n",
      "       I-GRP       0.58      0.44      0.50       226\n",
      "       I-LOC       0.23      0.11      0.15        61\n",
      "       I-PER       0.51      0.45      0.48       180\n",
      "      I-PROD       0.36      0.21      0.27       128\n",
      "           O       0.91      0.98      0.94      8648\n",
      "\n",
      "    accuracy                           0.86     10325\n",
      "   macro avg       0.42      0.30      0.34     10325\n",
      "weighted avg       0.82      0.86      0.84     10325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = cross_val_predict(estimator=crf, X=X, y=y, cv=5)\n",
    "report = flat_classification_report(y_pred=pred, y_true=y)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "169d5e2a-7765-4ca9-82f9-85ddd1238a03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-f68c206fd65d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meli5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meli5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/eli5/ipython.py\u001b[0m in \u001b[0;36mshow_weights\u001b[0;34m(estimator, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m    129\u001b[0m     \u001b[0mformat_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplain_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mexpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplain_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mexplain_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0m_set_html_kwargs_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_as_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    838\u001b[0m                             '1 positional argument')\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/eli5/sklearn_crfsuite/explain_weights.py\u001b[0m in \u001b[0;36mexplain_weights_sklearn_crfsuite\u001b[0;34m(crf, top, target_names, targets, feature_re, feature_filter)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[1;32m     28\u001b[0m     \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributes_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mstate_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf_state_coef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mtransition_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf_transition_coef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/eli5/sklearn_crfsuite/explain_weights.py\u001b[0m in \u001b[0;36mcrf_state_coef\u001b[0;34m(crf)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcrf_state_coef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mattr_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributes_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mclass_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "eli5.show_weights(crf, top=30)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
