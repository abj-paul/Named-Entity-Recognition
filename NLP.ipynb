{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd0a25cd-5fed-4392-b4ec-8e05357601c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c0354-38ea-4539-b75b-1729a66de3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db84760e-9a50-4feb-b097-442ffd27fe4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nlp_hackathon_bd_2023'...\n",
      "remote: Enumerating objects: 16, done.\u001b[K\n",
      "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
      "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
      "remote: Total 16 (delta 2), reused 12 (delta 2), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (16/16), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/cryptexcode/nlp_hackathon_bd_2023.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d2b7f90-d081-41b5-bd92-4426643eca55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE\t\t bengali_stemmer.egg-info  pytest.ini\t setup.py\n",
      "README.rst\t build\t\t\t   requirements  tests\n",
      "bengali_stemmer  nlp_hackathon_bd_2023\t   setup.cfg\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4375b8-d395-4706-b9b3-17cb0eb107ef",
   "metadata": {},
   "source": [
    "# Bayesian to get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c718546-1589-4251-b543-be5e1671dbef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.txt  train.txt\n"
     ]
    }
   ],
   "source": [
    "ls nlp_hackathon_bd_2023/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ec8b658-141b-4d2a-b1db-d7b72f884fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(\"nlp_hackathon_bd_2023/data/dev.txt\", \"r\")\n",
    "content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "055fe996-3d17-4cf9-b466-c9b4fc3fd5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['তিনি _ _ O', 'যুবক _ _ O', 'হিসেবে _ _ O', 'শেফিল্ড _ _ B-GRP', 'বুধবার _ _ I-GRP', 'এফ.সি. _ _ I-GRP', 'যোগদান _ _ O', 'করেন _ _ O', 'এবং _ _ O', '১৯৫১ _ _ O']\n"
     ]
    }
   ],
   "source": [
    "lines = content.split(\"\\n\")\n",
    "print(lines[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a1b2284-8a9e-4858-a826-3e8aef83c379",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['তিনি', ' O'], ['যুবক', ' O'], ['হিসেবে', ' O'], ['শেফিল্ড', ' B-GRP'], ['বুধবার', ' I-GRP'], ['এফ.সি.', ' I-GRP'], ['যোগদান', ' O'], ['করেন', ' O'], ['এবং', ' O'], ['১৯৫১', ' O']]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for line in lines:\n",
    "    parts = line.split(\" _\")\n",
    "    word = parts[0]\n",
    "    label = parts[len(parts)-1]\n",
    "    \n",
    "    dataset.append([word,label])\n",
    "print(dataset[:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b56d2d02-9052-41e3-bf2d-ac85c91c5a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4714 11132\n",
      "['তিনি', 'যুবক', 'হিসেবে', 'শেফিল্ড', 'বুধবার', 'এফ.সি.', 'যোগদান', 'করেন', 'এবং', '১৯৫১']\n"
     ]
    }
   ],
   "source": [
    "unique_words = []\n",
    "for row in dataset:\n",
    "    if row[0] not in unique_words:\n",
    "        unique_words.append(row[0])\n",
    "print(len(unique_words), len(dataset))\n",
    "print(unique_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb56ab-1a6d-4def-b9f3-37fc1cf18cae",
   "metadata": {},
   "source": [
    "Disparity between total rows and unique words are very little. As far as bayesian is concerned, stemming poses no problem so lets stem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d189090c-ef2c-42a9-8deb-93a86146b4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bengali-stemmer'...\n",
      "remote: Enumerating objects: 98, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
      "remote: Total 98 (delta 3), reused 2 (delta 2), pack-reused 94\u001b[K\n",
      "Unpacking objects: 100% (98/98), done.\n"
     ]
    }
   ],
   "source": [
    "# Installing Rafi Stemmer\n",
    "!git clone https://github.com/banglakit/bengali-stemmer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cfc20819-9c83-4dca-847a-08411554d236",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Getting_Started/bengali-stemmer/bengali-stemmer\n"
     ]
    }
   ],
   "source": [
    "cd bengali-stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51eec297-f3a1-433b-a57e-4183f2f8bf95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Processing /root/Getting_Started/bengali-stemmer/bengali-stemmer\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: bengali-stemmer\n",
      "  Building wheel for bengali-stemmer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bengali-stemmer: filename=bengali_stemmer-0.0.1-py2.py3-none-any.whl size=5535 sha256=a606c2188c5abf01271409cba103915560d02c3188466c48ed092a77d9676e2b\n",
      "  Stored in directory: /root/.cache/pip/wheels/75/ad/fb/7fc7332eb3ce8779922870961801a525c9882b567709415b25\n",
      "Successfully built bengali-stemmer\n",
      "Installing collected packages: bengali-stemmer\n",
      "  Attempting uninstall: bengali-stemmer\n",
      "    Found existing installation: bengali-stemmer 0.0.1\n",
      "    Uninstalling bengali-stemmer-0.0.1:\n",
      "      Successfully uninstalled bengali-stemmer-0.0.1\n",
      "Successfully installed bengali-stemmer-0.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c477d908-96d8-4414-b478-7bec8f24f3e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200 11132\n",
      "['তিনি', 'যুবক', 'হিসেব', 'শেফিল্ড', 'বুধব', 'এফ.সি.', 'যোগদান', 'কর', 'এবং', '১৯৫১']\n"
     ]
    }
   ],
   "source": [
    "from bengali_stemmer.rafikamal2014 import RafiStemmer\n",
    "stemmer = RafiStemmer()\n",
    "stemmer.stem_word('বাংলায়')\n",
    "\n",
    "unique_words = []\n",
    "for row in dataset:\n",
    "    stm = stemmer.stem_word(row[0])\n",
    "    if stm not in unique_words:\n",
    "        unique_words.append(stm)\n",
    "print(len(unique_words), len(dataset))\n",
    "print(unique_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db59c7f1-3359-4320-a123-534c8b588dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_array = defaultdict()\n",
    "no_array = defaultdict()\n",
    "\n",
    "for row in dataset:\n",
    "    if row[1] == \" O\""
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
