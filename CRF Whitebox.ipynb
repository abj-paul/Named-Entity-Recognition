{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "588ad624-bd44-4656-b09b-f424f697e070",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CRF Whitebox.ipynb'\t  bangla_word2vec\n",
      " F1Score.ipynb\t\t  bengali_cc_300d_bn_2.7.3_2.4_1612956925175.zip\n",
      " Getting_Started\t 'divide & conquer.ipynb'\n",
      "'Midnight dl nlp.ipynb'   nlp_hackathon_bd_2023\n",
      " Untitled.ipynb\t\t  nltk_data\n",
      " Untitled1.ipynb\t  untitled.flow\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d2a4d89-e544-4d50-891c-6631ce5c5a91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getDatasetFromIBOFile(filename): #nlp_hackathon_bd_2023/data/dev.txt\"\n",
    "    f = open(filename, \"r\")\n",
    "    content = f.read()\n",
    "    \n",
    "    lines = content.split(\"\\n\")\n",
    "    \n",
    "    dataset = []\n",
    "    for line in lines:\n",
    "        parts = line.split(\" _ _ \")\n",
    "        word = parts[0]\n",
    "        label = parts[len(parts)-1]\n",
    "\n",
    "        dataset.append([word,label])\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e4b9135-7a87-4014-9233-c3f3e357e469",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['তিনি', 'O'], ['যুবক', 'O'], ['হিসেবে', 'O'], ['শেফিল্ড', 'B-GRP'], ['বুধবার', 'I-GRP'], ['এফ.সি.', 'I-GRP'], ['যোগদান', 'O'], ['করেন', 'O'], ['এবং', 'O'], ['১৯৫১', 'O'], ['সালে', 'O'], ['তাদের', 'O'], ['পেশাগত', 'O'], ['দিক', 'O'], ['দিয়ে', 'O'], ['আত্মপ্রকাশ', 'O'], ['করেন।', 'O'], ['', ''], ['ভিনেগার', 'O'], ['মাঝে', 'O'], ['মাঝে', 'O'], ['চাটনি', 'B-PROD'], ['ব্যবহার', 'O'], ['করা', 'O'], ['হয়।', 'O'], ['', ''], ['মূলত,', 'O'], ['দুর্গটি', 'O'], ['ছিল', 'O'], ['একটি', 'O']]\n"
     ]
    }
   ],
   "source": [
    "dataset = getDatasetFromIBOFile(\"nlp_hackathon_bd_2023/data/dev.txt\")\n",
    "dataset = dataset[:int(len(dataset)*0.3)]\n",
    "print(dataset[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d002a77d-27da-43c9-8274-b8728a9f5543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: bltk in /opt/conda/lib/python3.7/site-packages (1.2)\n",
      "Requirement already satisfied: certifi>=2019.11.28 in /opt/conda/lib/python3.7/site-packages (from bltk) (2022.12.7)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from bltk) (1.4.1)\n",
      "Requirement already satisfied: nltk>=3.4.5 in /opt/conda/lib/python3.7/site-packages (from bltk) (3.7)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.7/site-packages (from bltk) (1.21.6)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from bltk) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from bltk) (0.22.1)\n",
      "Requirement already satisfied: sklearn>=0.0 in /opt/conda/lib/python3.7/site-packages (from bltk) (0.0.post1)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from bltk) (0.14.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk>=3.4.5->bltk) (4.42.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk>=3.4.5->bltk) (2022.10.31)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk>=3.4.5->bltk) (7.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0f3f964-5561-4d48-8475-dc2a410ac43b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.dict_vectorizer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction. Anything that cannot be imported from sklearn.feature_extraction is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DictVectorizer from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from bltk.langtools import PosTagger\n",
    "pos_tagger = PosTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e770bee-0a9b-4caf-ac9e-50c1ad0e32c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert data into features\n",
    "\n",
    "feature_extracted_dataset = []\n",
    "sentence = []\n",
    "for row in dataset:\n",
    "    word = row[0]\n",
    "    label = row[1]\n",
    "    if word=='':\n",
    "        feature_extracted_dataset.append(sentence)\n",
    "        sentence = []\n",
    "        continue\n",
    "    basic_word_features = (word, pos_tagger.pos_tag([word])[0][1], label)\n",
    "    sentence.append(basic_word_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f0d1342-2a1d-49e5-be99-600eea102523",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('তিনি', 'PPR', 'O'), ('যুবক', 'NC', 'O'), ('হিসেবে', 'PP', 'O'), ('শেফিল্ড', 'NP', 'B-GRP'), ('বুধবার', 'NC', 'I-GRP'), ('এফ.সি.', 'NP', 'I-GRP'), ('যোগদান', 'NC', 'O'), ('করেন', 'VM', 'O'), ('এবং', 'CCD', 'O'), ('১৯৫১', 'RDX', 'O'), ('সালে', 'NC', 'O'), ('তাদের', 'PPR', 'O'), ('পেশাগত', 'JJ', 'O'), ('দিক', 'NC', 'O'), ('দিয়ে', 'VM', 'O'), ('আত্মপ্রকাশ', 'NC', 'O'), ('করেন।', 'VM', 'O')], [('ভিনেগার', 'NC', 'O'), ('মাঝে', 'NST', 'O'), ('মাঝে', 'NST', 'O'), ('চাটনি', 'NC', 'B-PROD'), ('ব্যবহার', 'NC', 'O'), ('করা', 'NV', 'O'), ('হয়।', 'VM', 'O')], [('মূলত,', 'NC', 'O'), ('দুর্গটি', 'NC', 'O'), ('ছিল', 'VM', 'O'), ('একটি', 'JQ', 'O'), ('সুরক্ষিত', 'JJ', 'O'), ('দুর্গ,', 'PU', 'O'), ('যা', 'PRL', 'O'), ('পোলিশ', 'NC', 'B-LOC'), ('-লিথুয়ানিয়ান', 'NC', 'I-LOC'), ('কমনওয়েলথ', 'NP', 'I-LOC'), ('এর', 'PPR', 'O'), ('দক্ষিণ', 'JJ', 'O'), ('সীমান্ত', 'NC', 'O'), ('রক্ষা', 'NC', 'O'), ('করে।', 'VM', 'O')], [('হার্নান্দেজ', 'NC', 'O'), ('আলোকচিত্রগ্রাহী', 'NC', 'B-PROD'), ('ফিল্ম', 'NP', 'I-PROD'), ('ক্যামেরা', 'NC', 'O'), ('ব্যবহার', 'NC', 'O'), ('করা', 'NV', 'O'), ('অব্যাহত', 'JJ', 'O'), ('রেখেছেন,', 'PU', 'O'), ('যদিও', 'CSB', 'O'), ('তার', 'PPR', 'O'), ('প্রিন্ট', 'JJ', 'O'), ('ডিজিটালভাবে', 'AMN', 'O'), ('উৎপাদিত', 'JJ', 'O'), ('হয়।', 'VM', 'O')], [('ভ্যারাইটি', 'NC', 'B-CORP'), ('সিরিজের', 'NC', 'O'), ('উজ্জ্বল,', 'PU', 'O'), ('অনলস', 'NP', 'O'), ('চেহারা', 'NC', 'O'), ('এবং', 'CCD', 'O'), ('এমনকি', 'CSB', 'O'), ('তত্ত্বের', 'NC', 'O'), ('একটি', 'JQ', 'O'), ('আকর্ষণীয়', 'JJ', 'O'), ('ভিত্তির', 'NC', 'O'), ('প্রশংসা', 'NC', 'O'), ('করেছেন।', 'VM', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "print(feature_extracted_dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ae5ce-8bd3-45d3-9b7f-614a7d20bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpit koi vai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45f0088b-6903-4a95-9561-7c11b619f76b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def count_punctuations(text):\n",
    "    punctuations='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "    cnt = 0\n",
    "    for i in punctuations:\n",
    "        if i in text:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "print(count_punctuations(\"মূলত-প্রশংসা\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2406c132-2324-423d-aa1f-024d04a41e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        #'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        #'word.isupper()': word.isupper(),\n",
    "        #'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "        \"containPunctuation\": count_punctuations(word),\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            #'-1:word.lower()': word1.lower(),\n",
    "            #'-1:word.istitle()': word1.istitle(),\n",
    "            #'-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            #'+1:word.lower()': word1.lower(),\n",
    "            #'+1:word.istitle()': word1.istitle(),\n",
    "            #'+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e4d6bc7-5d38-4285-8461-7f131529fb6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in feature_extracted_dataset]\n",
    "y = [sent2labels(s) for s in feature_extracted_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e9752db-133e-4ee1-a356-c6e4011e8e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "592e2b02-b15d-4572-bd3c-99c42eaadb16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0.post1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8e7e1e7-d52e-4865-87e8-eadf56714130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe17150f-8a35-4431-b99b-f791d8dc9ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-CORP       0.15      0.06      0.09        34\n",
      "        B-CW       0.00      0.00      0.00        43\n",
      "       B-GRP       0.32      0.22      0.26        37\n",
      "       B-LOC       0.22      0.05      0.09        38\n",
      "       B-PER       0.34      0.24      0.29        49\n",
      "      B-PROD       0.15      0.04      0.06        49\n",
      "      I-CORP       0.19      0.08      0.11        37\n",
      "        I-CW       0.08      0.04      0.05        54\n",
      "       I-GRP       0.42      0.29      0.34        77\n",
      "       I-LOC       0.50      0.14      0.22        21\n",
      "       I-PER       0.36      0.24      0.29        62\n",
      "      I-PROD       0.08      0.03      0.04        33\n",
      "           O       0.89      0.98      0.93      2548\n",
      "\n",
      "    accuracy                           0.83      3082\n",
      "   macro avg       0.28      0.19      0.21      3082\n",
      "weighted avg       0.78      0.83      0.80      3082\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "pred = cross_val_predict(estimator=crf, X=X, y=y, cv=5)\n",
    "report = flat_classification_report(y_pred=pred, y_true=y)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3985766-aa13-49e8-9522-02c9fa18ed03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 250\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e6d7e-0466-4716-964b-de10b642f331",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0fd1b25-523c-452c-acbe-e09154e04431",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nlp_hackathon_bd_2023'...\n",
      "remote: Enumerating objects: 48, done.\u001b[K\n",
      "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
      "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
      "remote: Total 48 (delta 17), reused 36 (delta 9), pack-reused 0\n",
      "Unpacking objects: 100% (48/48), done.\n"
     ]
    }
   ],
   "source": [
    "!rm nlp_hackathon_bd_2023 -rf\n",
    "!git clone https://github.com/cryptexcode/nlp_hackathon_bd_2023.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e738fb87-dda6-4566-b47b-9b942447e778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getDatasetFromTestIBOFile(filename): #nlp_hackathon_bd_2023/data/dev.txt\"\n",
    "    f = open(filename, \"r\")\n",
    "    content = f.read()\n",
    "    \n",
    "    lines = content.split(\"\\n\")\n",
    "\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7845458b-2611-4169-a2e2-266b3c21648d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = getDatasetFromTestIBOFile(\"nlp_hackathon_bd_2023/data/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "056f8be8-7c92-4d81-9a80-e5eeccb32d24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13214\n"
     ]
    }
   ],
   "source": [
    "# Convert data into features\n",
    "\n",
    "feature_extracted_test_dataset = []\n",
    "sentence = []\n",
    "for row in test_dataset:\n",
    "    word = row\n",
    "    if word=='':\n",
    "        feature_extracted_test_dataset.append(sentence)\n",
    "        sentence = []\n",
    "        continue\n",
    "    basic_word_features = (word, pos_tagger.pos_tag([word])[0][1])\n",
    "    sentence.append(basic_word_features)\n",
    "print(len(feature_extracted_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3730dfef-5f56-4492-9358-1f878806ec6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 11\n"
     ]
    }
   ],
   "source": [
    "print(len(savior), len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85fbc13c-0084-4430-83e3-2e2d402842a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "savior = y[0]\n",
    "X = [sent2features(s) for s in feature_extracted_test_dataset]\n",
    "Y = [savior for d in range(13214)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "520766c8-37e4-45ed-a0bd-47acd2df00e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The numbers of items and labels differ: |x| = 18, |y| = 17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-5455227f8468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    753\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    754\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 755\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn_crfsuite/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_dev, y_dev)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.BaseTrainer.append\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The numbers of items and labels differ: |x| = 18, |y| = 17"
     ]
    }
   ],
   "source": [
    "pred = cross_val_predict(estimator=crf, X=X, y=Y, cv=5)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91930346-1a1e-48e0-bfbe-a21eb7e5cb63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(pred)):\n",
    "    for j in range(len(pred[i])):\n",
    "        print(pred[i][j])\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
