{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586f2624-2e8e-48e7-b77a-28ef58ee597e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: bnlp_toolkit in /opt/conda/lib/python3.7/site-packages (3.2.0)\n",
      "Requirement already satisfied: gensim==4.0.1 in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (4.0.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (1.4.1)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (3.7)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (1.21.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (4.42.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (0.1.97)\n",
      "Requirement already satisfied: wasabi in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (1.1.1)\n",
      "Requirement already satisfied: sklearn-crfsuite in /opt/conda/lib/python3.7/site-packages (from bnlp_toolkit) (0.3.6)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim==4.0.1->bnlp_toolkit) (6.3.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk->bnlp_toolkit) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->bnlp_toolkit) (0.14.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->bnlp_toolkit) (7.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->bnlp_toolkit) (1.14.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.8)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /opt/conda/lib/python3.7/site-packages (from wasabi->bnlp_toolkit) (4.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install bnlp_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49779a-62fc-4e0d-981c-0d5c3660d101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://huggingface.co/sagorsarker/bangla_word2vec/resolve/main/bangla_word2vec_gen4.zip\n",
    "!unzip bangla_word2vec_gen4.zip\n",
    "!rm -rf bangla_word2vec_gen4.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cd564e0-0238-4abe-95d0-e1718189037b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BengaliWord2Vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0a95b70984f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBengaliWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bangla_word2vec/bnwiki_word2vec.model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvectorize_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BengaliWord2Vec' is not defined"
     ]
    }
   ],
   "source": [
    "bwv = BengaliWord2Vec()\n",
    "model_path = \"bangla_word2vec/bnwiki_word2vec.model\"\n",
    "\n",
    "\n",
    "def vectorize_word(word):\n",
    "    return bwv.generate_word_vector(model_path, word)\n",
    "vectorize_word(\"নৃগোষ্ঠী\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf44cc-713d-453b-a6bf-131c54bc408d",
   "metadata": {},
   "source": [
    "### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54cf870-ae48-4d52-8b8e-7f2952eff8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def preprocess_word(word): ## hANDLE DARI ।\n",
    "  translate_table = dict((ord(char), None) for char in string.punctuation)   \n",
    "  word =  word.translate(translate_table)\n",
    "  return word.replace(\"।\", \"\")\n",
    "\n",
    "print(preprocess_word(\"পর,\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e2fda-e342-4d7c-87ac-d88777b65021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getDatasetFromIBOFile(filename): #nlp_hackathon_bd_2023/data/dev.txt\"\n",
    "    f = open(filename, \"r\")\n",
    "    content = f.read()\n",
    "    \n",
    "    lines = content.split(\"\\n\")\n",
    "    \n",
    "    dataset = []\n",
    "    for line in lines:\n",
    "        parts = line.split(\" _\")\n",
    "        word = parts[0]\n",
    "        word = preprocess_word(word)\n",
    "        label = parts[len(parts)-1]\n",
    "\n",
    "\n",
    "        # Special annoying cases\n",
    "        if word==\"ম্যাককম্ব\" or word=='' or word==\"ব্রাংম্যান\" or word=='ডাম্পসন': continue\n",
    "\n",
    "        dataset.append([word,label])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42ce1f-93e4-4750-9d63-14113f1cb768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encodeClass(Y):\n",
    "    classes = []\n",
    "    classes = [val for val in Y if val not in classes]\n",
    "    \n",
    "    new_y = []\n",
    "    for cls in Y:\n",
    "        for idx, val in enumerate(classes):\n",
    "            if cls==val:\n",
    "                new_y.append(idx)\n",
    "                break\n",
    "    return new_y\n",
    "                \n",
    "# encodeClass(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab30509-f2d7-4a96-a1aa-aed8843d3545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for row in dataset:\n",
    "      word = row[0]\n",
    "      label = row[1]\n",
    "\n",
    "      print(word)\n",
    "\n",
    "      X.append(vectorize_word(word))\n",
    "      Y.append(label)\n",
    "    \n",
    "    Y = encodeClass(Y)\n",
    "    \n",
    "    Y = np.array(Y)\n",
    "    X = np.array(X)\n",
    "    return X, Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b1f09-f433-481c-b7bc-0e6a62a118c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_SIZE = 100\n",
    "dataset = getDatasetFromIBOFile(\"nlp_hackathon_bd_2023/data/dev.txt\")[:DATA_SIZE]\n",
    "X, Y = preprocess_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73cc5be-5807-4428-b746-92974a85da0b",
   "metadata": {},
   "source": [
    "### Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33536b-aa7d-4ece-a14d-abf6e65403b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f98da-a5ef-4e4b-8bb2-8cef29faf902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cd6759-89aa-4ade-bcc3-4fbe8b3e4df8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(100, ), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27f506b-1faa-4f0a-9c3c-9fa99996225f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157e4c1-6ac8-44c3-a3b2-3dcadc87f1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69d751-fcd5-4462-9b28-535f7fbb4c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x=X, y=Y, batch_size=10, epochs=30, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9929bb8d-7b2d-485c-895f-39e190204dc2",
   "metadata": {},
   "source": [
    "### More Complex Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adafc5a8-cec6-45a1-89c8-34674d12f43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Dense(256, input_dim=100, activation=\"relu\", name=\"input\"),\n",
    "    layers.Dense(128, activation=\"relu\", name=\"layer1\"),\n",
    "    layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
    "    layers.Dense(5, activation=\"softmax\", name=\"output\")\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e74b0a-2c03-4790-8707-b82667ee3de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x=X, y=Y, batch_size=10, epochs=30, verbose=2, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
