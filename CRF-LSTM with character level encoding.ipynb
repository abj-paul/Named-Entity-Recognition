{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4e663737-624d-4f1d-8c04-5f8d7eb0f212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bangla_FastText_cbow.pickle\t bangla_word2vec\n",
      "'CRF For Bangla.ipynb'\t\t bangla_word2vec_gen4.zip\n",
      "'CRF for English.ipynb'\t\t bangla_word2vec_gen4.zip.1\n",
      " DeepLearning.ipynb\t\t bangla_word2vec_gen4.zip.2\n",
      " Getting_Started.ipynb\t\t bangla_word2vec_gen4.zip.3\n",
      "'Learning Deep Learning.ipynb'\t bengali-stemmer\n",
      " N.inb\t\t\t\t'dhanda nlp.ipynb'\n",
      " NLP.ipynb\t\t\t new-workspace.jupyterlab-workspace\n",
      " archive.zip\t\t\t nlp_hackathon_bd_2023\n",
      " bangla-fasttext\t\t word2vec.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "75fca457-d78b-4771-be70-962a245237a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getDatasetFromIBOFile(filename): #nlp_hackathon_bd_2023/data/dev.txt\"\n",
    "    f = open(filename, \"r\")\n",
    "    content = f.read()\n",
    "    \n",
    "    lines = content.split(\"\\n\")\n",
    "    \n",
    "    dataset = []\n",
    "    for line in lines:\n",
    "        parts = line.split(\" _ _ \")\n",
    "        word = parts[0]\n",
    "        label = parts[len(parts)-1]\n",
    "\n",
    "        dataset.append([word,label])\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "80c01fe1-0bc6-4531-b2fa-4a7998d80c37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['তিনি', 'O'], ['যুবক', 'O'], ['হিসেবে', 'O'], ['শেফিল্ড', 'B-GRP'], ['বুধবার', 'I-GRP'], ['এফ.সি.', 'I-GRP'], ['যোগদান', 'O'], ['করেন', 'O'], ['এবং', 'O'], ['১৯৫১', 'O'], ['সালে', 'O'], ['তাদের', 'O'], ['পেশাগত', 'O'], ['দিক', 'O'], ['দিয়ে', 'O'], ['আত্মপ্রকাশ', 'O'], ['করেন।', 'O'], ['', ''], ['ভিনেগার', 'O'], ['মাঝে', 'O'], ['মাঝে', 'O'], ['চাটনি', 'B-PROD'], ['ব্যবহার', 'O'], ['করা', 'O'], ['হয়।', 'O'], ['', ''], ['মূলত,', 'O'], ['দুর্গটি', 'O'], ['ছিল', 'O'], ['একটি', 'O']]\n"
     ]
    }
   ],
   "source": [
    "dataset = getDatasetFromIBOFile(\"nlp_hackathon_bd_2023/data/dev.txt\")\n",
    "print(dataset[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "124c62a7-07e4-454e-952c-5d7bb4ca3722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: bltk in /opt/conda/lib/python3.7/site-packages (1.2)\n",
      "Requirement already satisfied: nltk>=3.4.5 in /opt/conda/lib/python3.7/site-packages (from bltk) (3.7)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from bltk) (0.22.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from bltk) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.7/site-packages (from bltk) (1.21.6)\n",
      "Requirement already satisfied: sklearn>=0.0 in /opt/conda/lib/python3.7/site-packages (from bltk) (0.0.post1)\n",
      "Requirement already satisfied: certifi>=2019.11.28 in /opt/conda/lib/python3.7/site-packages (from bltk) (2022.12.7)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from bltk) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from bltk) (0.14.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk>=3.4.5->bltk) (4.42.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk>=3.4.5->bltk) (2022.10.31)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk>=3.4.5->bltk) (7.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "42857a69-4c48-4e8b-80cd-1908d2e197ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DictVectorizer from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from bltk.langtools import PosTagger\n",
    "pos_tagger = PosTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "de0607c6-9fd9-4d1a-a8c0-06656687424b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert data into features\n",
    "\n",
    "feature_extracted_dataset = []\n",
    "sentence = []\n",
    "for row in dataset:\n",
    "    word = row[0]\n",
    "    label = row[1]\n",
    "    if word=='':\n",
    "        feature_extracted_dataset.append(sentence)\n",
    "        sentence = []\n",
    "        continue\n",
    "    basic_word_features = (word, pos_tagger.pos_tag([word])[0][1], label)\n",
    "    sentence.append(basic_word_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6c2a1044-4615-4ef5-80f6-71f03b38a676",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('তিনি', 'PPR', 'O'), ('যুবক', 'NC', 'O'), ('হিসেবে', 'PP', 'O'), ('শেফিল্ড', 'NP', 'B-GRP'), ('বুধবার', 'NC', 'I-GRP'), ('এফ.সি.', 'NP', 'I-GRP'), ('যোগদান', 'NC', 'O'), ('করেন', 'VM', 'O'), ('এবং', 'CCD', 'O'), ('১৯৫১', 'RDX', 'O'), ('সালে', 'NC', 'O'), ('তাদের', 'PPR', 'O'), ('পেশাগত', 'JJ', 'O'), ('দিক', 'NC', 'O'), ('দিয়ে', 'VM', 'O'), ('আত্মপ্রকাশ', 'NC', 'O'), ('করেন।', 'VM', 'O')], [('ভিনেগার', 'NC', 'O'), ('মাঝে', 'NST', 'O'), ('মাঝে', 'NST', 'O'), ('চাটনি', 'NC', 'B-PROD'), ('ব্যবহার', 'NC', 'O'), ('করা', 'NV', 'O'), ('হয়।', 'VM', 'O')], [('মূলত,', 'NC', 'O'), ('দুর্গটি', 'NC', 'O'), ('ছিল', 'VM', 'O'), ('একটি', 'JQ', 'O'), ('সুরক্ষিত', 'JJ', 'O'), ('দুর্গ,', 'PU', 'O'), ('যা', 'PRL', 'O'), ('পোলিশ', 'NC', 'B-LOC'), ('-লিথুয়ানিয়ান', 'NC', 'I-LOC'), ('কমনওয়েলথ', 'NP', 'I-LOC'), ('এর', 'PPR', 'O'), ('দক্ষিণ', 'JJ', 'O'), ('সীমান্ত', 'NC', 'O'), ('রক্ষা', 'NC', 'O'), ('করে।', 'VM', 'O')], [('হার্নান্দেজ', 'NC', 'O'), ('আলোকচিত্রগ্রাহী', 'NC', 'B-PROD'), ('ফিল্ম', 'NP', 'I-PROD'), ('ক্যামেরা', 'NC', 'O'), ('ব্যবহার', 'NC', 'O'), ('করা', 'NV', 'O'), ('অব্যাহত', 'JJ', 'O'), ('রেখেছেন,', 'PU', 'O'), ('যদিও', 'CSB', 'O'), ('তার', 'PPR', 'O'), ('প্রিন্ট', 'JJ', 'O'), ('ডিজিটালভাবে', 'AMN', 'O'), ('উৎপাদিত', 'JJ', 'O'), ('হয়।', 'VM', 'O')], [('ভ্যারাইটি', 'NC', 'B-CORP'), ('সিরিজের', 'NC', 'O'), ('উজ্জ্বল,', 'PU', 'O'), ('অনলস', 'NP', 'O'), ('চেহারা', 'NC', 'O'), ('এবং', 'CCD', 'O'), ('এমনকি', 'CSB', 'O'), ('তত্ত্বের', 'NC', 'O'), ('একটি', 'JQ', 'O'), ('আকর্ষণীয়', 'JJ', 'O'), ('ভিত্তির', 'NC', 'O'), ('প্রশংসা', 'NC', 'O'), ('করেছেন।', 'VM', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "print(feature_extracted_dataset[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f91d95e-9bd1-45a1-838e-1788734d6f56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Old Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d04258b-89c3-442e-afc4-28acd5cd85cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def count_punctuations(text):\n",
    "    punctuations='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "    cnt = 0\n",
    "    for i in punctuations:\n",
    "        if i in text:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "print(count_punctuations(\"মূলত-প্রশংসা\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "42fecddf-b5fc-48da-a28d-56caef437de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        #'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        #'word.isupper()': word.isupper(),\n",
    "        #'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "        \"containPunctuation\": count_punctuations(word),\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            #'-1:word.lower()': word1.lower(),\n",
    "            #'-1:word.istitle()': word1.istitle(),\n",
    "            #'-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            #'+1:word.lower()': word1.lower(),\n",
    "            #'+1:word.istitle()': word1.istitle(),\n",
    "            #'+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c577d7b-c92a-4634-b8df-b768a4f819ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3cfc18ca-9892-4218-80db-0ad2002a3217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in feature_extracted_dataset]\n",
    "y = [sent2labels(s) for s in feature_extracted_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ea6bc68-0c3c-4610-b698-98b492f6a7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'bias': 1.0,\n",
       "   'word[-3:]': 'িনি',\n",
       "   'word[-2:]': 'নি',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PPR',\n",
       "   'postag[:2]': 'PP',\n",
       "   'containPunctuation': 0,\n",
       "   'BOS': True,\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'ুবক',\n",
       "   'word[-2:]': 'বক',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'PPR',\n",
       "   '-1:postag[:2]': 'PP',\n",
       "   '+1:postag': 'PP',\n",
       "   '+1:postag[:2]': 'PP'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'েবে',\n",
       "   'word[-2:]': 'বে',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PP',\n",
       "   'postag[:2]': 'PP',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'NP',\n",
       "   '+1:postag[:2]': 'NP'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'ল্ড',\n",
       "   'word[-2:]': '্ড',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NP',\n",
       "   'postag[:2]': 'NP',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'PP',\n",
       "   '-1:postag[:2]': 'PP',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'বার',\n",
       "   'word[-2:]': 'ার',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NP',\n",
       "   '-1:postag[:2]': 'NP',\n",
       "   '+1:postag': 'NP',\n",
       "   '+1:postag[:2]': 'NP'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'সি.',\n",
       "   'word[-2:]': 'ি.',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NP',\n",
       "   'postag[:2]': 'NP',\n",
       "   'containPunctuation': 1,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'দান',\n",
       "   'word[-2:]': 'ান',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NP',\n",
       "   '-1:postag[:2]': 'NP',\n",
       "   '+1:postag': 'VM',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'রেন',\n",
       "   'word[-2:]': 'েন',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VM',\n",
       "   'postag[:2]': 'VM',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'CCD',\n",
       "   '+1:postag[:2]': 'CC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'এবং',\n",
       "   'word[-2:]': 'বং',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'CCD',\n",
       "   'postag[:2]': 'CC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'VM',\n",
       "   '-1:postag[:2]': 'VM',\n",
       "   '+1:postag': 'RDX',\n",
       "   '+1:postag[:2]': 'RD'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': '৯৫১',\n",
       "   'word[-2:]': '৫১',\n",
       "   'word.isdigit()': True,\n",
       "   'postag': 'RDX',\n",
       "   'postag[:2]': 'RD',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'CCD',\n",
       "   '-1:postag[:2]': 'CC',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'ালে',\n",
       "   'word[-2:]': 'লে',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'RDX',\n",
       "   '-1:postag[:2]': 'RD',\n",
       "   '+1:postag': 'PPR',\n",
       "   '+1:postag[:2]': 'PP'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'দের',\n",
       "   'word[-2:]': 'ের',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'PPR',\n",
       "   'postag[:2]': 'PP',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'JJ',\n",
       "   '+1:postag[:2]': 'JJ'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'াগত',\n",
       "   'word[-2:]': 'গত',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'JJ',\n",
       "   'postag[:2]': 'JJ',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'PPR',\n",
       "   '-1:postag[:2]': 'PP',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'দিক',\n",
       "   'word[-2:]': 'িক',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'JJ',\n",
       "   '-1:postag[:2]': 'JJ',\n",
       "   '+1:postag': 'VM',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'য়ে',\n",
       "   'word[-2:]': '়ে',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VM',\n",
       "   'postag[:2]': 'VM',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'কাশ',\n",
       "   'word[-2:]': 'াশ',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'VM',\n",
       "   '-1:postag[:2]': 'VM',\n",
       "   '+1:postag': 'VM',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'েন।',\n",
       "   'word[-2:]': 'ন।',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VM',\n",
       "   'postag[:2]': 'VM',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   'EOS': True}],\n",
       " [{'bias': 1.0,\n",
       "   'word[-3:]': 'গার',\n",
       "   'word[-2:]': 'ার',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   'BOS': True,\n",
       "   '+1:postag': 'NST',\n",
       "   '+1:postag[:2]': 'NS'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'াঝে',\n",
       "   'word[-2:]': 'ঝে',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NST',\n",
       "   'postag[:2]': 'NS',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'NST',\n",
       "   '+1:postag[:2]': 'NS'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'াঝে',\n",
       "   'word[-2:]': 'ঝে',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NST',\n",
       "   'postag[:2]': 'NS',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NST',\n",
       "   '-1:postag[:2]': 'NS',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'টনি',\n",
       "   'word[-2:]': 'নি',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NST',\n",
       "   '-1:postag[:2]': 'NS',\n",
       "   '+1:postag': 'NC',\n",
       "   '+1:postag[:2]': 'NC'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'হার',\n",
       "   'word[-2:]': 'ার',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NC',\n",
       "   'postag[:2]': 'NC',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'NV',\n",
       "   '+1:postag[:2]': 'NV'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'করা',\n",
       "   'word[-2:]': 'রা',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'NV',\n",
       "   'postag[:2]': 'NV',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NC',\n",
       "   '-1:postag[:2]': 'NC',\n",
       "   '+1:postag': 'VM',\n",
       "   '+1:postag[:2]': 'VM'},\n",
       "  {'bias': 1.0,\n",
       "   'word[-3:]': 'য়।',\n",
       "   'word[-2:]': '়।',\n",
       "   'word.isdigit()': False,\n",
       "   'postag': 'VM',\n",
       "   'postag[:2]': 'VM',\n",
       "   'containPunctuation': 0,\n",
       "   '-1:postag': 'NV',\n",
       "   '-1:postag[:2]': 'NV',\n",
       "   'EOS': True}]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "581f62b0-94fc-4e6a-8291-c00bbabb26a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5be2d0cb-5363-4d8a-82f0-1f5f5842c39f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0.post1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e46fcafd-c6b0-471e-a068-7a66b8c014d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "be418288-72a6-4a09-842c-cfbd82bbcc86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-CORP       0.36      0.16      0.22       127\n",
      "        B-CW       0.10      0.03      0.04       120\n",
      "       B-GRP       0.47      0.34      0.39       118\n",
      "       B-LOC       0.40      0.23      0.29       101\n",
      "       B-PER       0.48      0.43      0.46       144\n",
      "      B-PROD       0.39      0.15      0.22       189\n",
      "      I-CORP       0.46      0.26      0.33       122\n",
      "        I-CW       0.24      0.07      0.11       161\n",
      "       I-GRP       0.58      0.44      0.50       226\n",
      "       I-LOC       0.23      0.11      0.15        61\n",
      "       I-PER       0.51      0.45      0.48       180\n",
      "      I-PROD       0.36      0.21      0.27       128\n",
      "           O       0.91      0.98      0.94      8648\n",
      "\n",
      "    accuracy                           0.86     10325\n",
      "   macro avg       0.42      0.30      0.34     10325\n",
      "weighted avg       0.82      0.86      0.84     10325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = cross_val_predict(estimator=crf, X=X, y=y, cv=5)\n",
    "report = flat_classification_report(y_pred=pred, y_true=y)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da62625-27f9-4956-ba0f-83eac92a808f",
   "metadata": {},
   "source": [
    "# New Model\n",
    "https://www.depends-on-the-definition.com/sequence-tagging-lstm-crf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dc123db6-d9d7-477b-8800-957bd8008694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = feature_extracted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6ce657a1-cf73-4738-91bb-c3d9daf6841e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['পরিচালনা', 'দুবার', '১৯৪২', 'কনস্ট্যান্স', 'অভিনেতা,', 'আকার', 'কাপড়ের', 'মারিয়া', 'প্রাসাদ', 'তারপরে,']\n"
     ]
    }
   ],
   "source": [
    "words = list(set(word[0] for sentence in data for word in sentence))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words); n_words\n",
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6939dce9-192e-40a6-8c2c-bc60e6c2a999",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(word[2] for sentence in data for word in sentence))\n",
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e0c5304e-60e5-4a10-bfc6-e56b58dd1d64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('তিনি', 'PPR', 'O'), ('যুবক', 'NC', 'O'), ('হিসেবে', 'PP', 'O'), ('শেফিল্ড', 'NP', 'B-GRP'), ('বুধবার', 'NC', 'I-GRP'), ('এফ.সি.', 'NP', 'I-GRP'), ('যোগদান', 'NC', 'O'), ('করেন', 'VM', 'O'), ('এবং', 'CCD', 'O'), ('১৯৫১', 'RDX', 'O'), ('সালে', 'NC', 'O'), ('তাদের', 'PPR', 'O'), ('পেশাগত', 'JJ', 'O'), ('দিক', 'NC', 'O'), ('দিয়ে', 'VM', 'O'), ('আত্মপ্রকাশ', 'NC', 'O'), ('করেন।', 'VM', 'O')]\n"
     ]
    }
   ],
   "source": [
    "sentences = data\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c9a962e4-db3f-43fd-bcd2-01193383b464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_len = 75\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bdb11d36-5d1e-421d-827c-f30c668758f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx[\"যুবক\"]\n",
    "tag2idx[\"O\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b25bc44-ba3b-44dd-b8e4-6dc93375f13a",
   "metadata": {},
   "source": [
    "### Prepare the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ee56d54a-ae7a-4129-82e1-4e057049019c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8f38e67e-82be-4e87-b940-463c28110792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "240c3381-ada7-4ce9-a560-e6079f72da87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c5b1171d-4de3-45c6-8e52-999a48b7b74b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "92beb1a5-4c82-488c-90ea-9563ba3010ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a2655b6f-402f-4f24-8d08-906c79ef83ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "eafc85bb-27ff-4bac-b30e-68eded4a2c52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1412  110  700 ...    0    0    0]\n",
      " [4662 2651   78 ...    0    0    0]\n",
      " [2654 2436 1270 ...    0    0    0]\n",
      " ...\n",
      " [ 946 3025 1270 ...    0    0    0]\n",
      " [4704 4647 3193 ...    0    0    0]\n",
      " [2869 2809 3192 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6aabeb94-c56a-44b2-92ee-e9ea62e603c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32), array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(y_tr[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f4438-4fcd-404a-be39-622c213ad5cc",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "aba420f4-9295-4c47-b636-c2b0d924b1a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODEOWNERS\t PULL_REQUEST_TEMPLATE.md  examples\t  tests\n",
      "CONTRIBUTING.md  README.md\t\t   keras_contrib\n",
      "GUIDELINES.md\t contrib_docs\t\t   pytest.ini\n",
      "LICENSE\t\t convert_to_tf_keras.py    setup.py\n"
     ]
    }
   ],
   "source": [
    "!ls keras-contrib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "78535741-a377-4807-999d-77379305cb5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: seqeval==0.0.5 in /opt/conda/lib/python3.7/site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval==0.0.5) (1.21.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mKeyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: keras==2.2.4 in /opt/conda/lib/python3.7/site-packages (2.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.4) (1.14.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.2.4) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.2.4) (6.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.4) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.4) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.4) (1.21.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mfatal: destination path 'keras-contrib' already exists and is not an empty directory.\n",
      " Bangla_FastText_cbow.pickle\t bangla_word2vec_gen4.zip\n",
      "'CRF For Bangla.ipynb'\t\t bangla_word2vec_gen4.zip.1\n",
      "'CRF for English.ipynb'\t\t bangla_word2vec_gen4.zip.2\n",
      " DeepLearning.ipynb\t\t bangla_word2vec_gen4.zip.3\n",
      " Getting_Started.ipynb\t\t bengali-stemmer\n",
      "'Learning Deep Learning.ipynb'\t'dhanda nlp.ipynb'\n",
      " N.inb\t\t\t\t keras-contrib\n",
      " NLP.ipynb\t\t\t new-workspace.jupyterlab-workspace\n",
      " archive.zip\t\t\t nlp_hackathon_bd_2023\n",
      " bangla-fasttext\t\t word2vec.ipynb\n",
      " bangla_word2vec\n",
      "running install\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  setuptools.SetuptoolsDeprecationWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/easy_install.py:159: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  EasyInstallDeprecationWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py:119: PkgResourcesDeprecationWarning: 4.0.0-unsupported is an invalid version and will not be supported in a future release\n",
      "  PkgResourcesDeprecationWarning,\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating keras_contrib.egg-info\n",
      "writing keras_contrib.egg-info/PKG-INFO\n",
      "writing dependency_links to keras_contrib.egg-info/dependency_links.txt\n",
      "writing requirements to keras_contrib.egg-info/requires.txt\n",
      "writing top-level names to keras_contrib.egg-info/top_level.txt\n",
      "writing manifest file 'keras_contrib.egg-info/SOURCES.txt'\n",
      "reading manifest file 'keras_contrib.egg-info/SOURCES.txt'\n",
      "writing manifest file 'keras_contrib.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
      "\n",
      "creating build\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying keras_contrib.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying keras_contrib.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying keras_contrib.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying keras_contrib.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying keras_contrib.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating dist\n",
      "creating 'dist/keras_contrib-2.0.8-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing keras_contrib-2.0.8-py3.7.egg\n",
      "Copying keras_contrib-2.0.8-py3.7.egg to /opt/conda/lib/python3.7/site-packages\n",
      "Adding keras-contrib 2.0.8 to easy-install.pth file\n",
      "\n",
      "Installed /opt/conda/lib/python3.7/site-packages/keras_contrib-2.0.8-py3.7.egg\n",
      "Processing dependencies for keras-contrib==2.0.8\n",
      "Searching for Keras==2.2.4\n",
      "Best match: Keras 2.2.4\n",
      "Adding Keras 2.2.4 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for six==1.14.0\n",
      "Best match: six 1.14.0\n",
      "Adding six 1.14.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for h5py==2.10.0\n",
      "Best match: h5py 2.10.0\n",
      "Adding h5py 2.10.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for Keras-Applications==1.0.8\n",
      "Best match: Keras-Applications 1.0.8\n",
      "Adding Keras-Applications 1.0.8 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for PyYAML==6.0\n",
      "Best match: PyYAML 6.0\n",
      "Adding PyYAML 6.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for Keras-Preprocessing==1.1.2\n",
      "Best match: Keras-Preprocessing 1.1.2\n",
      "Adding Keras-Preprocessing 1.1.2 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for numpy==1.21.6\n",
      "Best match: numpy 1.21.6\n",
      "Adding numpy 1.21.6 to easy-install.pth file\n",
      "Installing f2py script to /opt/conda/bin\n",
      "Installing f2py3 script to /opt/conda/bin\n",
      "Installing f2py3.7 script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for scipy==1.4.1\n",
      "Best match: scipy 1.4.1\n",
      "Adding scipy 1.4.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Finished processing dependencies for keras-contrib==2.0.8\n",
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: tensorflow==1.14.0 in /opt/conda/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.4.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.34.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (2.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.51.1)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (3.19.6)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.11.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.21.6)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (59.3.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (2.2.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (5.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (2.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.11.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/58498107/how-to-use-crf-in-tensorflow-keras\n",
    "!pip install seqeval==0.0.5\n",
    "!pip install keras==2.2.4\n",
    "\n",
    "!git clone https://www.github.com/keras-team/keras-contrib.git\n",
    "#!cd keras-contrib\n",
    "!ls\n",
    "!python keras-contrib/setup.py install\n",
    "\n",
    "!pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f2d2747b-c8a9-44d9-b95d-1fd46f6c04f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'keras-contrib'...\n",
      "remote: Enumerating objects: 2329, done.\u001b[K\n",
      "remote: Total 2329 (delta 0), reused 0 (delta 0), pack-reused 2329\u001b[K\n",
      "Receiving objects: 100% (2329/2329), 478.33 KiB | 8.70 MiB/s, done.\n",
      "Resolving deltas: 100% (1461/1461), done.\n",
      "running install\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  setuptools.SetuptoolsDeprecationWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/setuptools/command/easy_install.py:159: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  EasyInstallDeprecationWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py:119: PkgResourcesDeprecationWarning: 4.0.0-unsupported is an invalid version and will not be supported in a future release\n",
      "  PkgResourcesDeprecationWarning,\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing keras_contrib.egg-info/PKG-INFO\n",
      "writing dependency_links to keras_contrib.egg-info/dependency_links.txt\n",
      "writing requirements to keras_contrib.egg-info/requires.txt\n",
      "writing top-level names to keras_contrib.egg-info/top_level.txt\n",
      "reading manifest file 'keras_contrib.egg-info/SOURCES.txt'\n",
      "writing manifest file 'keras_contrib.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
      "\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying keras_contrib.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying keras_contrib.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying keras_contrib.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying keras_contrib.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying keras_contrib.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "creating 'dist/keras_contrib-2.0.8-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing keras_contrib-2.0.8-py3.7.egg\n",
      "Removing /opt/conda/lib/python3.7/site-packages/keras_contrib-2.0.8-py3.7.egg\n",
      "Copying keras_contrib-2.0.8-py3.7.egg to /opt/conda/lib/python3.7/site-packages\n",
      "keras-contrib 2.0.8 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /opt/conda/lib/python3.7/site-packages/keras_contrib-2.0.8-py3.7.egg\n",
      "Processing dependencies for keras-contrib==2.0.8\n",
      "Searching for Keras==2.2.4\n",
      "Best match: Keras 2.2.4\n",
      "Adding Keras 2.2.4 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for numpy==1.21.6\n",
      "Best match: numpy 1.21.6\n",
      "Adding numpy 1.21.6 to easy-install.pth file\n",
      "Installing f2py script to /opt/conda/bin\n",
      "Installing f2py3 script to /opt/conda/bin\n",
      "Installing f2py3.7 script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for h5py==2.10.0\n",
      "Best match: h5py 2.10.0\n",
      "Adding h5py 2.10.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for scipy==1.4.1\n",
      "Best match: scipy 1.4.1\n",
      "Adding scipy 1.4.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for six==1.14.0\n",
      "Best match: six 1.14.0\n",
      "Adding six 1.14.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for Keras-Preprocessing==1.1.2\n",
      "Best match: Keras-Preprocessing 1.1.2\n",
      "Adding Keras-Preprocessing 1.1.2 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for PyYAML==6.0\n",
      "Best match: PyYAML 6.0\n",
      "Adding PyYAML 6.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Searching for Keras-Applications==1.0.8\n",
      "Best match: Keras-Applications 1.0.8\n",
      "Adding Keras-Applications 1.0.8 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.7/site-packages\n",
      "Finished processing dependencies for keras-contrib==2.0.8\n"
     ]
    }
   ],
   "source": [
    "!rm keras-contrib -rf\n",
    "!git clone https://github.com/tsterbak/keras-contrib.git\n",
    "!python keras-contrib/setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "039d22b2-3c16-4848-a24b-ff8b55881eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8be839f0-a06d-40cb-b232-7d5fba800902",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling layer \"crf_6\" (type CRF).\n\nin user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\", line 292, in call  *\n        test_output = self.viterbi_decoding(X, mask)\n    File \"/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\", line 564, in viterbi_decoding  *\n        argmin_tables = self.recursion(input_energy, mask, return_logZ=False)\n    File \"/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\", line 521, in _step  *\n        return self.step(input_energy_i, states, return_logZ)\n    File \"/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\", line 463, in step  *\n        m = K.slice(states[3], [0, t], [-1, 2])\n\n    AttributeError: module 'keras.backend' has no attribute 'slice'\n\n\nCall arguments received by layer \"crf_6\" (type CRF):\n  • X=tf.Tensor(shape=(None, 75, 50), dtype=float32)\n  • mask=tf.Tensor(shape=(None, 75), dtype=bool)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-25f358da181c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# a dense layer as suggested by neuralNer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tags\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# CRF layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, X, mask)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mtest_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_marginal_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mtest_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'viterbi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'test_output'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\u001b[0m in \u001b[0;36mif_body_1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mif_body_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0;32mnonlocal\u001b[0m \u001b[0mtest_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0mtest_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviterbi_decoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0melse_body_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\u001b[0m in \u001b[0;36mtf__viterbi_decoding\u001b[0;34m(self, X, mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_boundary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'input_energy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0margmin_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_energy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_logZ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0margmin_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margmin_tables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0margmin_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margmin_tables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\u001b[0m in \u001b[0;36mtf__recursion\u001b[0;34m(self, input_energy, mask, go_backwards, return_sequences, return_logZ, input_length)\u001b[0m\n\u001b[1;32m     75\u001b[0m                             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mfscope_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval__1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_return_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mtarget_val_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_val_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_energy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mget_state_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(input_energy_i, states)\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                             \u001b[0mdo_return_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                             \u001b[0mretval__1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_energy_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_logZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                             \u001b[0mdo_return_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\u001b[0m in \u001b[0;36mtf__step\u001b[0;34m(self, input_energy_t, states, return_logZ)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'chain_energy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input_energy_t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mget_state_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\u001b[0m in \u001b[0;36mif_body_1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'theano'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                     \u001b[0minput_energy_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_energy_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mchain_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain_energy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\u001b[0m in \u001b[0;36melse_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0;32mdef\u001b[0m \u001b[0melse_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                         \u001b[0;32mnonlocal\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'theano'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling layer \"crf_6\" (type CRF).\n\nin user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\", line 292, in call  *\n        test_output = self.viterbi_decoding(X, mask)\n    File \"/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\", line 564, in viterbi_decoding  *\n        argmin_tables = self.recursion(input_energy, mask, return_logZ=False)\n    File \"/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\", line 521, in _step  *\n        return self.step(input_energy_i, states, return_logZ)\n    File \"/opt/conda/lib/python3.7/site-packages/keras_contrib/layers/crf.py\", line 463, in step  *\n        m = K.slice(states[3], [0, t], [-1, 2])\n\n    AttributeError: module 'keras.backend' has no attribute 'slice'\n\n\nCall arguments received by layer \"crf_6\" (type CRF):\n  • X=tf.Tensor(shape=(None, 75, 50), dtype=float32)\n  • mask=tf.Tensor(shape=(None, 75), dtype=bool)"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words + 1, output_dim=20,\n",
    "                  input_length=max_len, mask_zero=True)(input)  # 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags)  # CRF layer\n",
    "out = crf(model)  # output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79879885-5bdc-4750-a1b2-42e03a55da77",
   "metadata": {},
   "source": [
    "# Even more complex model\n",
    "The old model does not work for whatever reason so here we go again.\n",
    "\n",
    "https://www.depends-on-the-definition.com/lstm-with-char-embeddings-for-ner/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a6deeab7-c535-43d6-bbb4-6f6866137b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_len = 75\n",
    "max_len_char = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4a5aa88b-76b8-4ed1-a616-31e78d9c0674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1\n",
    "word2idx[\"PAD\"] = 0\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "tag2idx = {t: i + 1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "67c52d12-ab47-4d37-bbe1-a2216be17320",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx[\"যুবক\"]\n",
    "tag2idx[\"O\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87e618-ab40-49d4-ba8b-399881bd4612",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "50437831-4636-4fb1-b497-caeba5071ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_word = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X_word = pad_sequences(maxlen=max_len, sequences=X_word, value=word2idx[\"PAD\"], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ed694a4e-7e06-42f3-b2c4-10baa13569bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "chars = set([w_i for w in words for w_i in w])\n",
    "n_chars = len(chars)\n",
    "print(n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "677a30a3-4170-4d82-b6ca-e09a85be346a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
    "char2idx[\"UNK\"] = 1\n",
    "char2idx[\"PAD\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ea8c8499-b7bf-4256-9928-c735f33847d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-cf8dec169328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mword_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar2idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PAD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msent_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mX_char\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "X_char = []\n",
    "for sentence in sentences:\n",
    "    sent_seq = []\n",
    "    for i in range(max_len):\n",
    "        word_seq = []\n",
    "        for j in range(max_len_char):\n",
    "            try:\n",
    "                word_seq.append(char2idx.get(sentence[i][0][j]))\n",
    "            except:\n",
    "                word_seq.append(char2idx.get(\"PAD\"))\n",
    "        sent_seq.append(word_seq)\n",
    "    X_char.append(np.array(sent_seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e5d8e6-5b1b-4eb3-a1d3-c733031b7c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "39b6064f-a8f9-463e-a7c2-287c82490af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D\n",
    "from keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D\n",
    "\n",
    "word_in = Input(shape=(max_len,))\n",
    "emb_word = Embedding(input_dim=n_words + 2, output_dim=20,\n",
    "                     input_length=max_len, mask_zero=True)(word_in)\n",
    "\n",
    "# input and embeddings for characters\n",
    "char_in = Input(shape=(max_len, max_len_char,))\n",
    "emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2, output_dim=10,\n",
    "                           input_length=max_len_char, mask_zero=True))(char_in)\n",
    "# character LSTM to get word encodings by characters\n",
    "char_enc = TimeDistributed(LSTM(units=20, return_sequences=False,\n",
    "                                recurrent_dropout=0.5))(emb_char)\n",
    "\n",
    "# main LSTM\n",
    "x = concatenate([emb_word, char_enc])\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "main_lstm = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                               recurrent_dropout=0.6))(x)\n",
    "out = TimeDistributed(Dense(n_tags + 1, activation=\"sigmoid\"))(main_lstm)\n",
    "\n",
    "model = Model([word_in, char_in], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f1bdb20a-c84a-4a6c-a037-c227f99bd27e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)          [(None, 75, 10)]     0           []                               \n",
      "                                                                                                  \n",
      " input_13 (InputLayer)          [(None, 75)]         0           []                               \n",
      "                                                                                                  \n",
      " time_distributed_9 (TimeDistri  (None, 75, 10, 10)  70          ['input_14[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " embedding_11 (Embedding)       (None, 75, 20)       94260       ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " time_distributed_10 (TimeDistr  (None, 75, 20)      2480        ['time_distributed_9[0][0]']     \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 75, 40)       0           ['embedding_11[0][0]',           \n",
      "                                                                  'time_distributed_10[0][0]']    \n",
      "                                                                                                  \n",
      " spatial_dropout1d (SpatialDrop  (None, 75, 40)      0           ['concatenate[0][0]']            \n",
      " out1D)                                                                                           \n",
      "                                                                                                  \n",
      " bidirectional_7 (Bidirectional  (None, 75, 100)     36400       ['spatial_dropout1d[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " time_distributed_11 (TimeDistr  (None, 75, 14)      1414        ['bidirectional_7[0][0]']        \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 134,624\n",
      "Trainable params: 134,624\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9ccaf8a5-858b-4690-9d8c-a1b186822cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_word_tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-b174b8cd7dc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit([X_word_tr,\n\u001b[0m\u001b[1;32m      2\u001b[0m                      np.array(X_char_tr).reshape((len(X_char_tr), max_len, max_len_char))],\n\u001b[1;32m      3\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     batch_size=32, epochs=10, validation_split=0.1, verbose=1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_word_tr' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_word_tr,\n",
    "                     np.array(X_char_tr).reshape((len(X_char_tr), max_len, max_len_char))],\n",
    "                    np.array(y_tr).reshape(len(y_tr), max_len, 1),\n",
    "                    batch_size=32, epochs=10, validation_split=0.1, verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
