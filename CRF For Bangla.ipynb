{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e663737-624d-4f1d-8c04-5f8d7eb0f212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CRF For Bangla.ipynb'\t  N.inb         bengali-stemmer   nlp_hackathon_bd_2023\n",
      "'CRF for English.ipynb'   NLP.ipynb     ner.csv\n",
      " Getting_Started.ipynb\t  archive.zip   ner_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75fca457-d78b-4771-be70-962a245237a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getDatasetFromIBOFile(filename): #nlp_hackathon_bd_2023/data/dev.txt\"\n",
    "    f = open(filename, \"r\")\n",
    "    content = f.read()\n",
    "    \n",
    "    lines = content.split(\"\\n\")\n",
    "    \n",
    "    dataset = []\n",
    "    for line in lines:\n",
    "        parts = line.split(\" _ _ \")\n",
    "        word = parts[0]\n",
    "        label = parts[len(parts)-1]\n",
    "\n",
    "        dataset.append([word,label])\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80c01fe1-0bc6-4531-b2fa-4a7998d80c37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['তিনি', 'O'], ['যুবক', 'O'], ['হিসেবে', 'O'], ['শেফিল্ড', 'B-GRP'], ['বুধবার', 'I-GRP'], ['এফ.সি.', 'I-GRP'], ['যোগদান', 'O'], ['করেন', 'O'], ['এবং', 'O'], ['১৯৫১', 'O'], ['সালে', 'O'], ['তাদের', 'O'], ['পেশাগত', 'O'], ['দিক', 'O'], ['দিয়ে', 'O'], ['আত্মপ্রকাশ', 'O'], ['করেন।', 'O'], ['', ''], ['ভিনেগার', 'O'], ['মাঝে', 'O'], ['মাঝে', 'O'], ['চাটনি', 'B-PROD'], ['ব্যবহার', 'O'], ['করা', 'O'], ['হয়।', 'O'], ['', ''], ['মূলত,', 'O'], ['দুর্গটি', 'O'], ['ছিল', 'O'], ['একটি', 'O']]\n"
     ]
    }
   ],
   "source": [
    "dataset = getDatasetFromIBOFile(\"nlp_hackathon_bd_2023/data/dev.txt\")\n",
    "print(dataset[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "124c62a7-07e4-454e-952c-5d7bb4ca3722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting bltk\n",
      "  Downloading bltk-1.2.tar.gz (17.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: sklearn>=0.0 in /opt/conda/lib/python3.7/site-packages (from bltk) (0.0.post1)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from bltk) (1.14.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from bltk) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from bltk) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.7/site-packages (from bltk) (1.21.6)\n",
      "Requirement already satisfied: nltk>=3.4.5 in /opt/conda/lib/python3.7/site-packages (from bltk) (3.7)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from bltk) (0.14.1)\n",
      "Requirement already satisfied: certifi>=2019.11.28 in /opt/conda/lib/python3.7/site-packages (from bltk) (2022.9.24)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk>=3.4.5->bltk) (2022.10.31)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk>=3.4.5->bltk) (7.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk>=3.4.5->bltk) (4.42.1)\n",
      "Building wheels for collected packages: bltk\n",
      "  Building wheel for bltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bltk: filename=bltk-1.2-py3-none-any.whl size=17432539 sha256=3e3c1b3c0dce560ff15bae6f28fac44553fd36a31c0fef741ad0f319ceff26b4\n",
      "  Stored in directory: /root/.cache/pip/wheels/a4/ad/08/f3c5bb28b8bb02dd97973f1a4647bab68fea140ea11c0922b8\n",
      "Successfully built bltk\n",
      "Installing collected packages: bltk\n",
      "Successfully installed bltk-1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42857a69-4c48-4e8b-80cd-1908d2e197ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.dict_vectorizer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction. Anything that cannot be imported from sklearn.feature_extraction is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DictVectorizer from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from bltk.langtools import PosTagger\n",
    "pos_tagger = PosTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de0607c6-9fd9-4d1a-a8c0-06656687424b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert data into features\n",
    "\n",
    "feature_extracted_dataset = []\n",
    "sentence = []\n",
    "for row in dataset:\n",
    "    word = row[0]\n",
    "    label = row[1]\n",
    "    if word=='':\n",
    "        feature_extracted_dataset.append(sentence)\n",
    "        sentence = []\n",
    "        continue\n",
    "    basic_word_features = (word, pos_tagger.pos_tag([word])[0][1], label)\n",
    "    sentence.append(basic_word_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c2a1044-4615-4ef5-80f6-71f03b38a676",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('তিনি', 'PPR', 'O'), ('যুবক', 'NC', 'O'), ('হিসেবে', 'PP', 'O'), ('শেফিল্ড', 'NP', 'B-GRP'), ('বুধবার', 'NC', 'I-GRP'), ('এফ.সি.', 'NP', 'I-GRP'), ('যোগদান', 'NC', 'O'), ('করেন', 'VM', 'O'), ('এবং', 'CCD', 'O'), ('১৯৫১', 'RDX', 'O'), ('সালে', 'NC', 'O'), ('তাদের', 'PPR', 'O'), ('পেশাগত', 'JJ', 'O'), ('দিক', 'NC', 'O'), ('দিয়ে', 'VM', 'O'), ('আত্মপ্রকাশ', 'NC', 'O'), ('করেন।', 'VM', 'O')], [('ভিনেগার', 'NC', 'O'), ('মাঝে', 'NST', 'O'), ('মাঝে', 'NST', 'O'), ('চাটনি', 'NC', 'B-PROD'), ('ব্যবহার', 'NC', 'O'), ('করা', 'NV', 'O'), ('হয়।', 'VM', 'O')], [('মূলত,', 'NC', 'O'), ('দুর্গটি', 'NC', 'O'), ('ছিল', 'VM', 'O'), ('একটি', 'JQ', 'O'), ('সুরক্ষিত', 'JJ', 'O'), ('দুর্গ,', 'PU', 'O'), ('যা', 'PRL', 'O'), ('পোলিশ', 'NC', 'B-LOC'), ('-লিথুয়ানিয়ান', 'NC', 'I-LOC'), ('কমনওয়েলথ', 'NP', 'I-LOC'), ('এর', 'PPR', 'O'), ('দক্ষিণ', 'JJ', 'O'), ('সীমান্ত', 'NC', 'O'), ('রক্ষা', 'NC', 'O'), ('করে।', 'VM', 'O')], [('হার্নান্দেজ', 'NC', 'O'), ('আলোকচিত্রগ্রাহী', 'NC', 'B-PROD'), ('ফিল্ম', 'NP', 'I-PROD'), ('ক্যামেরা', 'NC', 'O'), ('ব্যবহার', 'NC', 'O'), ('করা', 'NV', 'O'), ('অব্যাহত', 'JJ', 'O'), ('রেখেছেন,', 'PU', 'O'), ('যদিও', 'CSB', 'O'), ('তার', 'PPR', 'O'), ('প্রিন্ট', 'JJ', 'O'), ('ডিজিটালভাবে', 'AMN', 'O'), ('উৎপাদিত', 'JJ', 'O'), ('হয়।', 'VM', 'O')], [('ভ্যারাইটি', 'NC', 'B-CORP'), ('সিরিজের', 'NC', 'O'), ('উজ্জ্বল,', 'PU', 'O'), ('অনলস', 'NP', 'O'), ('চেহারা', 'NC', 'O'), ('এবং', 'CCD', 'O'), ('এমনকি', 'CSB', 'O'), ('তত্ত্বের', 'NC', 'O'), ('একটি', 'JQ', 'O'), ('আকর্ষণীয়', 'JJ', 'O'), ('ভিত্তির', 'NC', 'O'), ('প্রশংসা', 'NC', 'O'), ('করেছেন।', 'VM', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "print(feature_extracted_dataset[:5])"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
